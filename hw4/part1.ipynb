{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "t84tK2fjAGux"
   },
   "source": [
    "# EECS 442 Homework 4: Fashion-MNIST Classification\n",
    "In this part, you will implement and train Convolutional Neural Networks (ConvNets) in PyTorch to classify images. Unlike HW4 Secion 1, backpropagation is automatically inferred by PyTorch, so you only need to write code for the forward pass.\n",
    "\n",
    "Before we start, please put your name and UMID in following format\n",
    "\n",
    ": Firstname LASTNAME, #00000000   //   e.g. David FOUHEY, #12345678"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zc0gjHQAGPs"
   },
   "source": [
    "**Your Answer:**   \n",
    "Yi-Cheng Liu #09466366"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8zMyTMC0VDm"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\whsje\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Run the command in the terminal if it failed on local Jupyter Notebook, remove \"!\" before each line\n",
    "!pip install torchsummary\n",
    "!conda install -c conda-forge pytorch-model-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mc2dzDlI_-6x"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # Displays a progress bar\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, Subset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvC_h1RpCuXN"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU. You are good to go!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"Using the CPU. Overall speed may be slowed down\")\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMKs1--aAe9c"
   },
   "source": [
    "## Loading Dataset\n",
    "The dataset we use is Fashion-MNIST dataset, which is available at https://github.com/zalandoresearch/fashion-mnist and in torchvision.datasets. Fashion-MNIST has 10 classes, 60000 training+validation images (we have splitted it to have 50000 training images and 10000 validation images, but you can change the numbers), and 10000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tbwq9R1cAbnc"
   },
   "outputs": [],
   "source": [
    "# Load the dataset and train, val, test splits\n",
    "print(\"Loading datasets...\")\n",
    "# Transform from [0,255] uint8 to [0,1] float,\n",
    "# then normalize to zero mean and unit variance\n",
    "FASHION_transform = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.2859], [0.3530]) \n",
    "                    ])\n",
    "FASHION_trainval = datasets.FashionMNIST('.', download=True, train=True,\n",
    "                                         transform=FASHION_transform)\n",
    "FASHION_train = Subset(FASHION_trainval, range(50000))\n",
    "FASHION_val = Subset(FASHION_trainval, range(50000, 60000))\n",
    "FASHION_test = datasets.FashionMNIST('.', download=True, train=False,\n",
    "                                     transform=FASHION_transform)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gqji7Q3XCIcY"
   },
   "source": [
    "Now, we will create the dataloder for train, val and test dataset. You are free to experiment with different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0KyRJWGCCgb"
   },
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "##############################################################################\n",
    "# TODO: Experiment with different batch sizes                                #\n",
    "##############################################################################\n",
    "batch_size=32\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################\n",
    "trainloader = DataLoader(FASHION_train, batch_size=batch_size, shuffle=True)\n",
    "valloader = DataLoader(FASHION_val, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(FASHION_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6rcDO7VCQ_q"
   },
   "source": [
    "## Model\n",
    "Initialize your model and experiment with with different optimizers, parameters (such as learning rate) and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hz0BSR9xCNiX"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ##############################################################################\n",
    "        # TODO: Design your own network, define layers here.                          #\n",
    "        # Here We provide a sample of two-layer fc network from HW4 Part3.           #\n",
    "        # Your solution, however, should contain convolutional layers.               #\n",
    "        # Refer to PyTorch documentations of torch.nn to pick your layers.           #\n",
    "        # (https://pytorch.org/docs/stable/nn.html)                                  #\n",
    "        # Some common choices: Linear, Conv2d, ReLU, MaxPool2d, AvgPool2d, Dropout   #\n",
    "        # If you have many layers, use nn.Sequential() to simplify your code         #\n",
    "        ##############################################################################\n",
    "        # from 28x28 input image to hidden layer of size 256\n",
    "        self.fc1 = nn.Linear(28*28, 8) \n",
    "        # from hidden layer to 10 class scores\n",
    "        self.fc2 = nn.Linear(8,10) \n",
    "        ##############################################################################\n",
    "        #                             END OF YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "  \n",
    "    def forward(self, x):\n",
    "        ##############################################################################\n",
    "        # TODO: Design your own network, implement forward pass here                 # \n",
    "        ##############################################################################\n",
    "        x = x.to(device)\n",
    "        # Flatten each image in the batch\n",
    "        x = x.view(-1,28*28) \n",
    "        x = self.fc1(x)\n",
    "        # No need to define self.relu because it contains no parameters\n",
    "        relu = nn.ReLU() \n",
    "        x = relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # The loss layer will be applied outside Network class\n",
    "        return x\n",
    "        ##############################################################################\n",
    "        #                             END OF YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "\n",
    "model = Network().to(device)\n",
    "criterion = nn.CrossEntropyLoss() # Specify the loss layer\n",
    "print('Your network:')\n",
    "print(summary(model, (1,28,28), device=device)) # visualize your model\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Modify the lines below to experiment with different optimizers,      #\n",
    "# parameters (such as learning rate) and number of epochs.                   #\n",
    "##############################################################################\n",
    "# Set up optimization hyperparameters\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "num_epoch = 10  # TODO: Choose an appropriate number of training epochs\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                       weight_decay=weight_decay) # Try different optimizers\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq9fTZiuDJ3I"
   },
   "source": [
    "Run the cell below to start your training, we expect you to achieve over **85%** on the test set. A valid solution that meet the requirement take no more than **10 minutes** on normal PC Intel core CPU setting. If your solution takes too long to train, try to simplify your model or reduce the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOFaEvBDDHzQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def train(model, trainloader, valloader, num_epoch=10):  # Train the model\n",
    "    print(\"Start training...\")\n",
    "    trn_loss_hist = []\n",
    "    trn_acc_hist = []\n",
    "    val_acc_hist = []\n",
    "    model.train()  # Set the model to training mode\n",
    "    for i in range(num_epoch):\n",
    "        running_loss = []\n",
    "        print('-----------------Epoch = %d-----------------' % (i+1))\n",
    "        for batch, label in tqdm(trainloader):\n",
    "            batch = batch.to(device)\n",
    "            label = label.to(device)\n",
    "            optimizer.zero_grad()  # Clear gradients from the previous iteration\n",
    "            # This will call Network.forward() that you implement\n",
    "            pred = model(batch)\n",
    "            loss = criterion(pred, label)  # Calculate the loss\n",
    "            running_loss.append(loss.item())\n",
    "            loss.backward()  # Backprop gradients to all tensors in the network\n",
    "            optimizer.step()  # Update trainable weights\n",
    "        print(\"\\n Epoch {} loss:{}\".format(i+1, np.mean(running_loss)))\n",
    "\n",
    "        # Keep track of training loss, accuracy, and validation loss\n",
    "        trn_loss_hist.append(np.mean(running_loss))\n",
    "        trn_acc_hist.append(evaluate(model, trainloader))\n",
    "        print(\"\\n Evaluate on validation set...\")\n",
    "        val_acc_hist.append(evaluate(model, valloader))\n",
    "    print(\"Done!\")\n",
    "    return trn_loss_hist, trn_acc_hist, val_acc_hist\n",
    "\n",
    "\n",
    "def evaluate(model, loader):  # Evaluate accuracy on validation / test set\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    with torch.no_grad():  # Do not calculate grident to speed up computation\n",
    "        for batch, label in tqdm(loader):\n",
    "            batch = batch.to(device)\n",
    "            label = label.to(device)\n",
    "            pred = model(batch)\n",
    "            correct += (torch.argmax(pred, dim=1) == label).sum().item()\n",
    "        acc = correct/len(loader.dataset)\n",
    "        print(\"\\n Evaluation accuracy: {}\".format(acc))\n",
    "        return acc\n",
    "\n",
    "\n",
    "trn_loss_hist, trn_acc_hist, val_acc_hist = train(model, trainloader,\n",
    "                                                  valloader, num_epoch)\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Note down the evaluation accuracy on test set                        #\n",
    "##############################################################################\n",
    "print(\"\\n Evaluate on test set\")\n",
    "evaluate(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwDhwaydQR1Q"
   },
   "source": [
    "Once your training is complete, run the cell below to visualize the training and validation accuracies across iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lYqngdtPQB8"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# TODO: Submit the accuracy plot                                             #\n",
    "##############################################################################\n",
    "# visualize the training / validation accuracies\n",
    "x = np.arange(num_epoch)\n",
    "# train/val accuracies for MiniVGG\n",
    "plt.figure()\n",
    "plt.plot(x, trn_acc_hist)\n",
    "plt.plot(x, val_acc_hist)\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.xticks(x)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('fashion MNIST Classification')\n",
    "plt.gcf().set_size_inches(10, 5)\n",
    "plt.savefig('part1.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPMybiGiTlZDBY4uaeomg3n",
   "collapsed_sections": [],
   "name": "part1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9d34995e9b9aacf7236904ea7ddf7585a36f6be47e873dd30641939c3248d078"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
